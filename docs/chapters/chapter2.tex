\chapter{Теоретические аспекты решения }

В этой главе поднимаются некоторые теоретические аспекты решения.
Описываются, какие признаки использовались для построения классификатора.
Также подробно говорится о типах машинного обучения, использующихся при решении задачи.

\section{Выбор признаков}

Для построения классификатора были выбраны более 50 признаков.
Полная информация о них представлена в приложении A.
Здесь будет лишь частично рассказано о признаках в общем.

Признаки, выбранные для построения классификатора можно разбить на следующие категории:

\begin{enumerate}
	\item Количественные признаки (количество заказов, транспортных средств, водителей, локаций в одном наборе данных)
	\item Матрицы совместимости (например, между исполнителем-транспортом, транспортом-локацией, исполнителем-заказом, грузом-отсеком траспнортного средства и т.д.)
	\item Статистические признаки (например, среднее количество рабочих смен для исполнителей, среднее количество грузов в заказах, средняя длительность временного отрезка в минутах (для исполнителя) \ длительность пути в метрах для транспорта и т.д.)
	\item Геокоординаты
\end{enumerate}

Иногда в машинном обучении первоначально делают отбор признаков, чтобы сократить их число при построении классификатора.
В данном случае, этого делать не нужно, потому что классов наборов данных не так много.

\section{Типы многоклассовой классификации}

При решении данной задачи будут использоваться различные типы классификация.
Посколько решение основано на разбивание элементов на достаточно большое число классов, то многие методы классификации плохо подходят для машинного обучения.
Об это также сказано в \cite{many-classes}.
Например, тяжело решать эту задача наивным Байесом или k-ближайшими соседями.

Про поиск эффективных методов снижения размерности при решении задач многоклассовой классификации путем ее сведения к решению бинарных задач хорошо говорится в \cite{many-binary}

Ниже будут расписаны методы, которые использовались для построения классификатора. 
Все они считаются достаточно удачными для работы со многими классами.

\subsection{Дерево Решений. Алгоритм C4.5}

Про деревья решений хорошо рассказано в \cite{tree-rus} и \cite{tree-eng}.

Для того, чтобы с помощью C4.5 построить решающее дерево и применять его для классификации, данные должны удовлетворять нескольким условиям, о которых речь пойдет в дальнейшем.

Информация об датасетах, которые надо классифицировать, должна быть представлена в виде конечного набора атрибутов, каждый из которых имеет либо дискретное значение, либо числовое значение.
Такой набор атрибутов назовём тестовой частью. 
В данном исследовании используются только числовые.
Для всех примеров количество примеров и их состав должны быть const.

Множество категорий, на которые будут разбиваться примеры, должно иметь конечное число объектов, а каждый атрибут должен однозначно относиться к конкретной категории.

В обучающей выборке количество атрибутов должно быть сильно больше количества категорий, к тому же каждый атрибут должен быть заранее соотнесен со своим классом.
Без этого грамотного построения дерева не получится.

Пусть имеется $D$ ~--- обучающая выборка примеров, а $S$ ~--- множество классов, состоящее из $t$ элементов. Для каждого атрибута из $D$ известна его принадлежность к какому-либо из классов $S_1 \ldots S_t$.

На первом шаге имеется корень и соотнесенное с ним множество $D$, которое необходимо разбить на подмножества. Для этого надо выбрать один из примеров в качестве сверки. Выбранный пример $V$ имеет $t$ значений, что разбивает множество на $t$ подмножеств. Далее создаются $t$ потомков корня, каждому из которых соотносятся своё подмножество, полученное при разбиении $D$. Процедура выбора примера и разбиения по нему рекурсивно применяется ко всем $t$ потомкам и останавливается только в следующих случаях:

\begin{itemize}
	\item Вершина оказалась ассоциированной с пустым множеством (тогда она становится листом, а в качестве решения выбирается наиболее часто встречающийся класс у предка этой вершины).
	\item После очередного ветвления в вершине оказываются примеры из одного класса (тогда она, то есть вершина, становится листом, а класс, которому принадлежат её примеры, будет именоваться решением листа);
\end{itemize}

\subsection{Многоклассовый метод опорных векторов}

Про обычный SVM хорошо рассказано в \cite{svm-vorontsov}.

Суть заключается в решении нескольких бинарных задач: последовательного отделения первого класса от остальных, второго класса от оставшихся и т.д., или выделения каждого класса из всего множества. После решения этих бинарных задач получается несколько обученных SVM, соответствующих каждому классу. Далее при определении класса нового объекта каждая SVM вернет коэффициент принадлежности, и класс объекта будет определен по максимальному значению этого коэффициента. Хорошо про это рассказано в \cite{svm-moreee}.

Такой подход в машинном обучении называется <<Один против всех>>.
Более подробно можно ознакомиться в \cite{much}.

\subsection{Многоклассовая логистическая регрессия}

Про обычную логистическую регрессию можно почитать в \cite{regression-vorontsov}.

По поводу многоклассовой можно сказать,что это она схоже с предыдущим пунктом.
Только в данном случае после решения бинарных задач получается несколько обученных логистических регрессий, соответствующих каждому классу.
По вероятностям и будет определен класс объекта.


\subsection{Random Forest}

RF (random forest) — это множество решающих деревьев.В задаче классификации принимается решение голосованием по большинству. Все деревья строятся независимо по следующей схеме:

\begin{itemize}
	\item Выбирается подвыборка обучающей выборки определенного размера  ~--- по ней строится дерево (для каждого дерева ~--- своя подвыборка);
	\item Для построения каждого расщепления в дереве просматривается максимальное число случайных признаков (для каждого нового расщепления ~--- свои случайные признаки);
	\item Выбирается наилучшие признак и расщепление по нему (по заранее заданному критерию). Дерево строится, как правило, до исчерпания выборки (пока в листьях не останутся представители только одного класса).
\end{itemize}

\chapterconclusion

В этой главе говорилось о теоретической области решения данной задачи.
Рассказывается о признаках, которые были выбраны для построения классификатора.
Выделены их основные типы.
Также приводится описание методов классификации, которые используются при машинном обучении в данной задаче.